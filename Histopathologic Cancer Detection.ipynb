{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af8558a",
   "metadata": {},
   "source": [
    "## Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c119c",
   "metadata": {},
   "source": [
    "### Challenge Problem\n",
    "\n",
    "This challenge involves identifying metastatic cancer in small image patches from digital pathology scans, a binary classification task where images are labeled as cancerous (1) or non-cancerous (0). The key challenges include handling .tif images, managing tissue appearance variability, addressing class imbalance, and ensuring proper feature extraction for accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8cc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e080d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2455912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the training labels\n",
    "labels_df = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b7cc416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1561a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.405031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.490899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label\n",
       "count  220025.000000\n",
       "mean        0.405031\n",
       "std         0.490899\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "062f8e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220025 entries, 0 to 220024\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      220025 non-null  object\n",
      " 1   label   220025 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f70c694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='label', data=labels_df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4dd7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59.496875\n",
      "1    40.503125\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Percentage of each class\n",
    "class_distribution = labels_df['label'].value_counts(normalize=True) * 100\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c70ddf",
   "metadata": {},
   "source": [
    "### Desciption of the Data\n",
    "\n",
    "The dataset contains 220,025 unique image samples, each labeled as either 0 or 1, indicating a binary classification task. The class distribution shows that label 0 (the majority class) appears roughly 60% of the time (130,908 instances), while label 1 (the minority class) appears about 40% of the time (89,117 instances). Although the class imbalance is not extreme, it is significant enough to impact model evaluation.\n",
    "\n",
    "While accuracy measures the overall correctness of the model, it can be misleading in the presence of class imbalance. Therefore, it is important to also consider precision and recall. Precision measures the correctness of positive predictions, ensuring a low false positive rate, while recall measures the model's ability to identify all relevant instances, ensuring a low false negative rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3848e",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "The primary data cleaning task involves preparing the image files for use with the ImageDataGenerator and associated functions in TensorFlow. The only adjustment needed is appending \".tif\" to the end of each label ID to correctly reference the image files during the data loading process. Another importamt mpte os that the dataset does not contain any missing values, so no imputation or removal of missing data is necessary.\n",
    "\n",
    "As mentioned in the description of the data, there is a slight imbalance in the data. Before making any adjustments to the dataset to address class imbalance, we will evaluate the precision and recall of our models. This approach allows us to understand how well the model performs across different classes and whether the imbalance significantly impacts performance. \n",
    "\n",
    "The plan for this analysis is to utilize the ImageDataGenerator from TensorFlow.keras to load and preprocess the images, including rescaling pixel values and applying data augmentation techniques to enhance the training data. We will implement a Convolutional Neural Network (CNN) using TensorFlow.keras, starting with a simple model and iteratively refining it to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add .tif to the end of every label ID\n",
    "labels_df['label'] = labels_df['label'].astype(str)\n",
    "labels_df['id'] = labels_df['id'].apply(lambda x: x + '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c5f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerator for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5624936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 154018 validated image filenames belonging to 2 classes.\n",
      "Found 66007 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation generators\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory='train',\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=512,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=labels_df,\n",
    "    directory='train',\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=512,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53078996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c511a1a",
   "metadata": {},
   "source": [
    "### Begininning Model Architecture\n",
    "\n",
    "The model architecture consists of three convolutional layers with ReLU activation and increasing filter sizes (32, 64, 128), each followed by max-pooling layers to reduce spatial dimensions and computational complexity. These layers have the ability to learn spatial hierarchies of features. The use of ReLU activation introduces non-linearity, allowing the model to capture more complex patterns in the images.\n",
    "\n",
    "After flattening the output from the convolutional layers, the model has a dense layer with 128 neurons and ReLU activation, followed by a single neuron with a sigmoid activation for binary classification. This combination allows the model to effectively combine and classify the features extracted from the images, outputting a probability score indicating the presence or absence of cancer. The chosen architecture effectively balances complexity and efficiency. This makes it suitable for the histopathologic cancer detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f67927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1cd8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the first model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2974c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "301/301 [==============================] - 362s 1s/step - loss: 0.4895 - accuracy: 0.7675 - precision: 0.7372 - recall: 0.6624 - val_loss: 0.4596 - val_accuracy: 0.7903 - val_precision: 0.8043 - val_recall: 0.6363\n",
      "Epoch 2/6\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.4410 - accuracy: 0.7990 - precision: 0.7662 - recall: 0.7255 - val_loss: 0.4170 - val_accuracy: 0.8170 - val_precision: 0.7856 - val_recall: 0.7532\n",
      "Epoch 3/6\n",
      "301/301 [==============================] - 347s 1s/step - loss: 0.4081 - accuracy: 0.8172 - precision: 0.7977 - recall: 0.7355 - val_loss: 0.3967 - val_accuracy: 0.8255 - val_precision: 0.7675 - val_recall: 0.8157\n",
      "Epoch 4/6\n",
      "301/301 [==============================] - 400s 1s/step - loss: 0.3910 - accuracy: 0.8256 - precision: 0.8053 - recall: 0.7513 - val_loss: 0.3971 - val_accuracy: 0.8224 - val_precision: 0.7490 - val_recall: 0.8435\n",
      "Epoch 5/6\n",
      "301/301 [==============================] - 389s 1s/step - loss: 0.3743 - accuracy: 0.8346 - precision: 0.8139 - recall: 0.7674 - val_loss: 0.3664 - val_accuracy: 0.8417 - val_precision: 0.8143 - val_recall: 0.7885\n",
      "Epoch 6/6\n",
      "301/301 [==============================] - 359s 1s/step - loss: 0.3647 - accuracy: 0.8394 - precision: 0.8174 - recall: 0.7773 - val_loss: 0.3526 - val_accuracy: 0.8461 - val_precision: 0.8316 - val_recall: 0.7768\n"
     ]
    }
   ],
   "source": [
    "# Train the first model using the generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=6,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a13b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 95s 736ms/step - loss: 0.3526 - accuracy: 0.8461 - precision: 0.8316 - recall: 0.7768\n",
      "Validation Accuracy: 0.85\n",
      "Validation Precision: 0.83\n",
      "Validation Recall: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Calculate the validation loss and accuracy for the first model\n",
    "val_loss, val_acc, val_precision, val_recall = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_acc:.2f}')\n",
    "print(f'Validation Precision: {val_precision:.2f}')\n",
    "print(f'Validation Recall: {val_recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa560ef",
   "metadata": {},
   "source": [
    "### Second Model Iteration\n",
    "\n",
    "In this second iteration of the model, we will incorporate batch normalization to protentially improve the accuracy, precision, and recall of the model. Batch normalization helps the model converge faster and more reliably to an optimal solution. This will ideally result in better generalization on unseen data, which could potenially enhance the model's ability to accurately classify images, leading to higher accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae01fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b59882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f275388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "301/301 [==============================] - 553s 2s/step - loss: 0.4106 - accuracy: 0.8163 - precision_1: 0.7937 - recall_1: 0.7388 - val_loss: 1.0676 - val_accuracy: 0.5832 - val_precision_1: 0.4915 - val_recall_1: 0.8744\n",
      "Epoch 2/6\n",
      "301/301 [==============================] - 355s 1s/step - loss: 0.3429 - accuracy: 0.8506 - precision_1: 0.8321 - recall_1: 0.7911 - val_loss: 0.6553 - val_accuracy: 0.7247 - val_precision_1: 0.6029 - val_recall_1: 0.9355\n",
      "Epoch 3/6\n",
      "301/301 [==============================] - 351s 1s/step - loss: 0.3062 - accuracy: 0.8700 - precision_1: 0.8529 - recall_1: 0.8208 - val_loss: 0.5716 - val_accuracy: 0.8006 - val_precision_1: 0.7007 - val_recall_1: 0.8849\n",
      "Epoch 4/6\n",
      "301/301 [==============================] - 348s 1s/step - loss: 0.2838 - accuracy: 0.8809 - precision_1: 0.8656 - recall_1: 0.8361 - val_loss: 0.6684 - val_accuracy: 0.7424 - val_precision_1: 0.7964 - val_recall_1: 0.4878\n",
      "Epoch 5/6\n",
      "301/301 [==============================] - 350s 1s/step - loss: 0.2651 - accuracy: 0.8890 - precision_1: 0.8744 - recall_1: 0.8479 - val_loss: 0.3386 - val_accuracy: 0.8518 - val_precision_1: 0.7839 - val_recall_1: 0.8747\n",
      "Epoch 6/6\n",
      "301/301 [==============================] - 347s 1s/step - loss: 0.2440 - accuracy: 0.8988 - precision_1: 0.8850 - recall_1: 0.8624 - val_loss: 1.0271 - val_accuracy: 0.6890 - val_precision_1: 0.9328 - val_recall_1: 0.2491\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the generators\n",
    "history_2 = model_2.fit(\n",
    "    train_generator,\n",
    "    epochs=6,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4292cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 89s 691ms/step - loss: 1.0271 - accuracy: 0.6890 - precision_1: 0.9328 - recall_1: 0.2491\n",
      "Validation Accuracy: 0.69\n",
      "Validation Precision: 0.93\n",
      "Validation Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "val_loss_2, val_acc_2, val_precision_2, val_recall_2 = model_2.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_acc_2:.2f}')\n",
    "print(f'Validation Precision: {val_precision_2:.2f}')\n",
    "print(f'Validation Recall: {val_recall_2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968cba7",
   "metadata": {},
   "source": [
    "### Third Model Iteration\n",
    "\n",
    "In this third iteration we will replace the flatten and dense layers with global average pooling to reduce the number of parameters and prevent overfitting. Global average pooling condenses the spatial dimensions of the feature maps into a more compact representation. This change can enhance the model's generalization, hopefullly improving accuracy, precision, and recall. This approach emphasizes the most important features and reduces the potential of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06b3230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_3 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    GlobalAveragePooling2D(),  # Replaces Flatten and Dense layers\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b21cc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "100ef4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "301/301 [==============================] - 364s 1s/step - loss: 0.4101 - accuracy: 0.8180 - precision_2: 0.7976 - recall_2: 0.7384 - val_loss: 0.6930 - val_accuracy: 0.6084 - val_precision_2: 0.5093 - val_recall_2: 0.8720\n",
      "Epoch 2/6\n",
      "301/301 [==============================] - 358s 1s/step - loss: 0.3573 - accuracy: 0.8438 - precision_2: 0.8308 - recall_2: 0.7717 - val_loss: 0.6928 - val_accuracy: 0.7448 - val_precision_2: 0.6364 - val_recall_2: 0.8609\n",
      "Epoch 3/6\n",
      "301/301 [==============================] - 362s 1s/step - loss: 0.3217 - accuracy: 0.8624 - precision_2: 0.8511 - recall_2: 0.8007 - val_loss: 0.6376 - val_accuracy: 0.7729 - val_precision_2: 0.6591 - val_recall_2: 0.9081\n",
      "Epoch 4/6\n",
      "301/301 [==============================] - 364s 1s/step - loss: 0.2991 - accuracy: 0.8727 - precision_2: 0.8629 - recall_2: 0.8154 - val_loss: 0.3919 - val_accuracy: 0.8341 - val_precision_2: 0.7532 - val_recall_2: 0.8773\n",
      "Epoch 5/6\n",
      "301/301 [==============================] - 365s 1s/step - loss: 0.2836 - accuracy: 0.8806 - precision_2: 0.8708 - recall_2: 0.8283 - val_loss: 2.3211 - val_accuracy: 0.6612 - val_precision_2: 0.9820 - val_recall_2: 0.1655\n",
      "Epoch 6/6\n",
      "301/301 [==============================] - 362s 1s/step - loss: 0.2690 - accuracy: 0.8880 - precision_2: 0.8792 - recall_2: 0.8388 - val_loss: 0.4951 - val_accuracy: 0.8132 - val_precision_2: 0.8464 - val_recall_2: 0.6576\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the generators\n",
    "history_3 = model_3.fit(\n",
    "    train_generator,\n",
    "    epochs=6,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4152b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 94s 732ms/step - loss: 0.4951 - accuracy: 0.8132 - precision_2: 0.8464 - recall_2: 0.6576\n",
      "Validation Accuracy: 0.81\n",
      "Validation Precision: 0.85\n",
      "Validation Recall: 0.66\n"
     ]
    }
   ],
   "source": [
    "val_loss_3, val_acc_3, val_precision_3, val_recall_3 = model_3.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_acc_3:.2f}')\n",
    "print(f'Validation Precision: {val_precision_3:.2f}')\n",
    "print(f'Validation Recall: {val_recall_3:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442882c",
   "metadata": {},
   "source": [
    "### Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61fc8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Model\": [\"Model 1\", \"Model 2\", \"Model 3\"],\n",
    "    \"Precision\": [val_precision, val_precision_2, val_precision_3],\n",
    "    \"Recall\": [val_recall, val_recall_2, val_recall_3],\n",
    "    \"Accuracy\": [val_acc, val_acc_2, val_acc_3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11400c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Precision    Recall  Accuracy\n",
      "0  Model 1   0.831576  0.776754  0.846077\n",
      "1  Model 2   0.932810  0.249092  0.689033\n",
      "2  Model 3   0.846391  0.657565  0.813232\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "models_df = pd.DataFrame(models)\n",
    "\n",
    "# Display the table\n",
    "print(models_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9aae3",
   "metadata": {},
   "source": [
    "<b>Why the Baseline Performed Well:</b> The baseline architecture (Model 1) demonstrated a well-balanced performance with precision, recall, and accuracy metrics of 0.831576, 0.776754, and 0.846077, respectively. This suggests that the model effectively identified true positives while maintaining a relatively low rate of false positives, making it suitable for applications where both precision and recall are critical.\n",
    "\n",
    "<b>Improvements with Batch Normalization:</b> Introducing batch normalization (Model 2) significantly increased precision to 0.932810 but led to a marked decrease in recall and accuracy, with values of 0.249092 and 0.689033, respectively. This indicates that while the model was highly confident when predicting positive cases, it failed to identify a substantial number of true positives. The likely cause is overfitting or poor generalization to the validation data.\n",
    "\n",
    "<b>Impact of Global Average Pooling:</b> Incorporating global average pooling in place of flatten and dense layers (Model 3) resulted in a more balanced performance with precision, recall, and accuracy metrics of 0.846391, 0.657565, and 0.813232, respectively. Although the precision and recall were slightly lower compared to Model 1, the reduction in overfitting and enhanced generalization provided a more consistent and reliable performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af61be",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This analysis showed that different architectures and techniques have varying impacts on model performance. The baseline model (Model 1) had the best balance between precision, recall, and accuracy, making it reliable for medical diagnostics. Model 2, with batch normalization, achieved high precision but very low recall and accuracy, indicating potential overfitting. Model 3, with global average pooling, provided a better trade-off between precision and recall while maintaining reasonable accuracy. These findings highlight the need to balance accuracy, precision, and recall based on application requirements. Further tuning, such as optimizing learning rates, experimenting with different optimizers, and employing more sophisticated augmentation techniques, could enhance performance. However, these efforts would require significant time and computational power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed8144",
   "metadata": {},
   "source": [
    "### Procudeure to get the Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8179fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [file for file in os.listdir('test') if file.endswith('.tif')]\n",
    "test_df = pd.DataFrame({'filename': test_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7db5998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd0a060ef9c30c9a83f6b4bfb568db74b099154d.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f9ee06f06d329eb7902a2e03ab3835dd0484581.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19709bec800f372d0b1d085da6933dd3ef108846.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a34fc34523063f13f0617f7518a0330f6187bd3.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93be720ca2b95fe2126cf2e1ed752bd759e9b0ed.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename\n",
       "0  fd0a060ef9c30c9a83f6b4bfb568db74b099154d.tif\n",
       "1  1f9ee06f06d329eb7902a2e03ab3835dd0484581.tif\n",
       "2  19709bec800f372d0b1d085da6933dd3ef108846.tif\n",
       "3  7a34fc34523063f13f0617f7518a0330f6187bd3.tif\n",
       "4  93be720ca2b95fe2126cf2e1ed752bd759e9b0ed.tif"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe72097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf0c8a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57458 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Flow from DataFrame for test data\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='test',\n",
    "    x_col='filename',\n",
    "    y_col=None,  # No labels for test data\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode=None,  # No labels for test data\n",
    "    shuffle=False  # Don't shuffle for test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ab2671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062e31ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa960969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission file\n",
    "filenames = test_generator.filenames\n",
    "test_ids = [os.path.splitext(os.path.basename(f))[0] for f in filenames]\n",
    "submission_df = pd.DataFrame({'id': test_ids, 'label': predicted_labels})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eac4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
